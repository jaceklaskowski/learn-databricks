{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e74b20b9-5d52-4e9f-a458-30a656b4c917",
   "metadata": {},
   "source": [
    "[Connect to Spark Connect server](https://spark.apache.org/docs/latest/api/python/getting_started/quickstart_connect.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16cb6a37-c5b0-4203-8a61-067648aa7a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.remote(\"sc://localhost:15002\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "120de679-c924-4e78-a40f-19e31c0c2b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d69b7d8-7cd8-47b3-a80c-a1bff908048e",
   "metadata": {},
   "source": [
    "[Quickstart: DataFrame](https://spark.apache.org/docs/latest/api/python/getting_started/quickstart_df.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7acd54-7a02-4a02-93f3-16751f2813e4",
   "metadata": {},
   "source": [
    "Use [Faker](https://faker.readthedocs.io/en/master/) to generate fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5827362d-9856-4c76-8329-85cf9b2202b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "fake = Faker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11a1c41f-b1b6-43b8-ae7e-1dadf9dbcae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+\n",
      "| id|          name|\n",
      "+---+--------------+\n",
      "|  0|Christina Dean|\n",
      "|  1|Christina Dean|\n",
      "|  2|Christina Dean|\n",
      "|  3|Christina Dean|\n",
      "|  4|Christina Dean|\n",
      "+---+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "names_df = spark.range(5).withColumn('name', lit(fake.name()))\n",
    "names_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ad58713-8c51-4a12-b3c4-4196ae98a588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Daniel Mcdonald', 'April Kelly', 'Mark Conway', 'Rebecca Johnson', 'Brian Clay MD']\n"
     ]
    }
   ],
   "source": [
    "names = []\n",
    "for _ in range(5):\n",
    "  names.append(fake.name())\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d5c8d72-3413-46a6-9867-e00a997647af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|           name|\n",
      "+---------------+\n",
      "|Daniel Mcdonald|\n",
      "|    April Kelly|\n",
      "|    Mark Conway|\n",
      "|Rebecca Johnson|\n",
      "|  Brian Clay MD|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names_df = spark.createDataFrame(names, ['name'])\n",
    "names_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fba6adae-d302-43c7-9f2a-f2e89ac03751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "\n",
    "@udf\n",
    "def generate_name() -> str:\n",
    "    return fake.name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "296a1e36-2a9c-424b-a3cc-b52b33034023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+\n",
      "| id|           name|\n",
      "+---+---------------+\n",
      "|  0|William Mcguire|\n",
      "|  1|William Mcguire|\n",
      "|  2|William Mcguire|\n",
      "|  3|William Mcguire|\n",
      "|  4|William Mcguire|\n",
      "+---+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names_df = spark.range(5).withColumn('name', generate_name())\n",
    "names_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2026d0-0b9a-4f82-b4f5-643d501c7c39",
   "metadata": {},
   "source": [
    "It is highly likely that the above cell breaks due to incompatible Python versions on the driver and executors.\n",
    "\n",
    "Use `PYSPARK_PYTHON` to align the Python versions.\n",
    "\n",
    "We're using `poetry` to manage the Python version on the driver.\n",
    "\n",
    "```console\n",
    "$ poetry env info\n",
    "Virtualenv\n",
    "Python:         3.12.5\n",
    "Implementation: CPython\n",
    "Path:           /Users/jacek/Library/Caches/pypoetry/virtualenvs/jupyter-spark-CV1FMzPj-py3.12\n",
    "Executable:     /Users/jacek/Library/Caches/pypoetry/virtualenvs/jupyter-spark-CV1FMzPj-py3.12/bin/python\n",
    "Valid:          True\n",
    "\n",
    "System\n",
    "Platform:   darwin\n",
    "OS:         posix\n",
    "Python:     3.12.5\n",
    "Path:       /usr/local/opt/python@3.12/Frameworks/Python.framework/Versions/3.12\n",
    "Executable: /usr/local/opt/python@3.12/Frameworks/Python.framework/Versions/3.12/bin/python3.12\n",
    "```\n",
    "\n",
    "With the above, `PYSPARK_PYTHON` should use the path of `Executable` of the `Virtualenv` section.\n",
    "\n",
    "Stop the Spark Connect server.\n",
    "\n",
    "```bash\n",
    "./sbin/stop-connect-server.sh\n",
    "```\n",
    "\n",
    "Set `PYSPARK_PYTHON` environment variable.\n",
    "\n",
    "```bash\n",
    "export PYSPARK_PYTHON=/Users/jacek/Library/Caches/pypoetry/virtualenvs/jupyter-spark-CV1FMzPj-py3.12/bin/python\n",
    "```\n",
    "\n",
    "```bash\n",
    "./sbin/start-connect-server.sh\n",
    "```\n",
    "\n",
    "Restart the cell above and it should work fine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdef55f3-1d3b-4e27-a693-b5dcc0e59597",
   "metadata": {},
   "source": [
    "QUESTION: Why does the output contain the same names among the rows?\n",
    "\n",
    "Read **Notes** in [pyspark.sql.functions.udf](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.udf.html):\n",
    "\n",
    "> The user-defined functions are considered deterministic by default.\n",
    "> Due to optimization, duplicate invocations may be eliminated or the function may even be invoked more times than it is present in the query.\n",
    "> If your function is not deterministic, call `asNondeterministic` on the user defined function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0f0445f-0d08-46ab-bb2a-09864fbb7fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "generate_name_udf = udf(lambda: fake.name(), StringType()).asNondeterministic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5433800a-d06f-4f0a-84fc-fbc3ee73b4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+\n",
      "| id|           name|\n",
      "+---+---------------+\n",
      "|  0|William Mcguire|\n",
      "|  1|William Mcguire|\n",
      "|  2|William Mcguire|\n",
      "|  3|William Mcguire|\n",
      "|  4|William Mcguire|\n",
      "+---+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names_df = spark.range(5).withColumn('name', generate_name_udf())\n",
    "names_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aa2f4d-dbb8-471d-92aa-d8dd6be41d75",
   "metadata": {},
   "source": [
    "It does not work either! ðŸ˜¢\n",
    "\n",
    "`faker.Factory` seems the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af88e29d-9a84-439f-9e70-b8c0c8d6b722",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from faker import Factory\n",
    "\n",
    "@udf\n",
    "def fake_name():\n",
    "    faker = Factory.create()\n",
    "    return faker.name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bdce0719-3002-4ffa-a8f0-bdcfdcd0f0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+\n",
      "| id|            name|\n",
      "+---+----------------+\n",
      "|  0|       John Cook|\n",
      "|  1|     Tanya Crane|\n",
      "|  2|Brooke Villa DDS|\n",
      "|  3|    Julian Velez|\n",
      "|  4| Angelica Malone|\n",
      "+---+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names_df = spark.range(5).withColumn('name', fake_name())\n",
    "names_df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
