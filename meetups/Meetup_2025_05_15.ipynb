{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a68f0afc-f0c6-420b-912e-e88c0e45be7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Meetup Next\n",
    "\n",
    "This notebook should help you set up your next great meetup.\n",
    "\n",
    "1. Fill in the fields with **FIXME** marker\n",
    "1. Announce the meetup\n",
    "    * [lu.ma](https://lu.ma/warsaw-data-engineering)\n",
    "    * [LinkedIn](https://www.linkedin.com/groups/9307761/)\n",
    "    * (Optionally) [meetup](https://www.meetup.com/warsaw-data-engineering/) for a greater visibility\n",
    "1. Remove this cell once all the action items are done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a46b538-5343-4bc0-b5fc-97449b4aa283",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# MLflow on Databricks cntd.\n",
    "\n",
    "FIXME Thursday, February 27, 2025\n",
    "\n",
    "FIXME [Invitation on Luma](https://lu.ma/warsaw-data-engineering), [LinkedIn](https://www.linkedin.com/groups/9307761/), [Meetup](https://www.meetup.com/warsaw-data-engineering/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd081a26-c5e2-444a-875d-64c485221a95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# FIXME Agenda\n",
    "\n",
    "1. FIXME\n",
    "\n",
    "Ca≈Çkowity czas trwania spotkania: **1h 15min**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4b536d7-e189-45af-a05a-88e502572df4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# FIXME LinkedIn Poll\n",
    "\n",
    "[Poll](https://www.linkedin.com/feed/update/urn:li:activity:7302063410647638016?utm_source=share&utm_medium=member_desktop&rcm=ACoAAAAutA8BdJM8iCUgt2VrqrjL8sihttmw9FE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0099d7a7-078c-4a57-8671-dcd404040811",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# FIXME Event Question\n",
    "\n",
    "O czym chcia≈Ç(a)by≈õ us≈Çyszeƒá podczas meetupu? Rzuƒá ciekawym pomys≈Çem na kolejne edycje üôè\n",
    "\n",
    "1. FIXME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "811aaee2-66d6-4833-84d3-c5971e3359ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üì¢ News\n",
    "\n",
    "Things worth watching out for..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6c1a71ee-100f-48c0-b82a-e8b535208dea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## FIXME New members in Warsaw Data Engineering!\n",
    "\n",
    "[You now have 591 members!](https://www.meetup.com/warsaw-data-engineering/)\n",
    "\n",
    "Co zainteresowa≈Ço Ciƒô w Warsaw Data Engineering Meetup, ≈ºe zdecydowa≈Ça≈õ/-e≈õ siƒô przy≈ÇƒÖczyƒá?\n",
    "\n",
    "1. FIXME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "911c3ac7-09bf-45dd-9a57-2d8de1c5aa67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## FIXME New Versions\n",
    "\n",
    "What has changed in the tooling space since we last met? I.e. hunting down the features to learn more about.\n",
    "\n",
    "* [Databricks CLI 0.242.0](https://github.com/databricks/cli/releases/tag/v0.242.0)\n",
    "* [MLflow 2.20.3](https://github.com/mlflow/mlflow/releases/tag/v2.20.3)\n",
    "* [uv 0.6.3](https://github.com/astral-sh/uv/releases/tag/0.6.3)\n",
    "* [Pydantic 2.10.6](https://github.com/pydantic/pydantic/releases/tag/v2.10.6)\n",
    "* [brickflow 1.3.2](https://github.com/Nike-Inc/brickflow/releases/tag/v1.3.2)\n",
    "* [dqx 0.1.13](https://github.com/databrickslabs/dqx/releases/tag/v0.1.13)\n",
    "* [ruff 0.9.9](https://github.com/astral-sh/ruff/releases/tag/0.9.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "581fa336-7db9-41d6-9817-62ea8141564d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Managed MLflow on Databricks\n",
    "\n",
    "It all started with [Manage model lifecycle in Unity Catalog](https://docs.databricks.com/aws/en/machine-learning/manage-model-lifecycle/) and [Tutorials: Get started with AI and machine learning](https://docs.databricks.com/aws/en/machine-learning/ml-tutorials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "35a777ff-5745-4612-a9e6-a2f29055f9c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Discovery of the Day\n",
    "\n",
    "A Data Engineer's take on the matters:\n",
    "\n",
    "> The key is to think about **model training workload** as a Python code and **ML model** as a directory with a bunch of files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "36d83ee7-ec8d-475e-a04d-7ac7968f350a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "```py\n",
    "mlflow.start_run()\n",
    "\n",
    "model_run = mlflow.active_run()\n",
    "\n",
    "mlflow.end_run()\n",
    "\n",
    "print(model_run.info)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2bddc7bf-6a68-49b3-a9b1-206521163043",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# MLflow's examples/databricks\n",
    "\n",
    "[examples/databricks](https://github.com/mlflow/mlflow/tree/master/examples/databricks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2dd1e1dd-ae87-4e4c-9e75-5322517cddba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Step 0. Clone MLflow Repo\n",
    "\n",
    "`git clone` https://github.com/mlflow/mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec36fa11-c5bd-44b4-b60d-3eb8ec2b9db1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Step 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "074a9c61-ac03-460b-8f42-d2f8ca971c48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "```\n",
    "uv pip install databricks-connect\n",
    "uv pip install scikit-learn\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1907d1aa-32ae-489b-93b4-69383cefb86a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Step 2. Run Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f2c503b0-7a97-43e3-a462-351a1b5b99fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "```\n",
    "‚ùØ python examples/databricks/dbconnect.py --cluster-id xxx\n",
    "2025/05/08 17:51:04 INFO mlflow.tracking.fluent: Experiment with name '/Users/jacek@japila.pl/dbconnect' does not exist. Creating a new experiment.\n",
    "üèÉ View run smiling-ox-667 at: https://curriculum-dev.cloud.databricks.com/ml/experiments/1275781889574864/runs/b88fd8406e7d410bac8992258093ef5d\n",
    "üß™ View experiment at: https://curriculum-dev.cloud.databricks.com/ml/experiments/1275781889574864\n",
    "Traceback (most recent call last):\n",
    "  File \"/Users/jacek/oss/mlflow/examples/databricks/dbconnect.py\", line 56, in <module>\n",
    "    main()\n",
    "    ~~~~^^\n",
    "  File \"/Users/jacek/oss/mlflow/examples/databricks/dbconnect.py\", line 37, in main\n",
    "    model_info = mlflow.sklearn.log_model(model, name=\"model\", signature=signature)\n",
    "TypeError: log_model() got an unexpected keyword argument 'name'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b70015d-5f12-409b-b1dd-03a35102d9be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Step 3. Editable Install\n",
    "\n",
    "[Development Mode (a.k.a. ‚ÄúEditable Installs‚Äù)](https://setuptools.pypa.io/en/latest/userguide/development_mode.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c28c8ba-8695-4f0d-a32a-fc8724c3ab53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "```\n",
    "uv pip install -e .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3704eff-2fd7-47b5-960f-cb3cf5744398",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "```\n",
    "‚ùØ python examples/databricks/dbconnect.py --cluster-id xxx\n",
    "üèÉ View run carefree-duck-680 at: https://curriculum-dev.cloud.databricks.com/ml/experiments/1275781889574864/runs/89a774fb54da4a5c844764d3e40ad638\n",
    "üß™ View experiment at: https://curriculum-dev.cloud.databricks.com/ml/experiments/1275781889574864\n",
    "Traceback (most recent call last):\n",
    "  File \"/Users/jacek/oss/mlflow/examples/databricks/dbconnect.py\", line 56, in <module>\n",
    "    main()\n",
    "    ~~~~^^\n",
    "  File \"/Users/jacek/oss/mlflow/examples/databricks/dbconnect.py\", line 37, in main\n",
    "    model_info = mlflow.sklearn.log_model(model, name=\"model\", signature=signature)\n",
    "  File \"/Users/jacek/oss/mlflow/mlflow/sklearn/__init__.py\", line 426, in log_model\n",
    "    return Model.log(\n",
    "           ~~~~~~~~~^\n",
    "        artifact_path=artifact_path,\n",
    "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "    ...<18 lines>...\n",
    "        model_id=model_id,\n",
    "        ^^^^^^^^^^^^^^^^^^\n",
    "    )\n",
    "    ^\n",
    "  File \"/Users/jacek/oss/mlflow/mlflow/models/model.py\", line 928, in log\n",
    "    model = mlflow.initialize_logged_model(\n",
    "        # TODO: Update model name\n",
    "    ...<6 lines>...\n",
    "        else None,\n",
    "    )\n",
    "  File \"/Users/jacek/oss/mlflow/mlflow/tracking/fluent.py\", line 2122, in initialize_logged_model\n",
    "    model = _create_logged_model(\n",
    "        name=name,\n",
    "    ...<4 lines>...\n",
    "        experiment_id=experiment_id,\n",
    "    )\n",
    "  File \"/Users/jacek/oss/mlflow/mlflow/tracking/fluent.py\", line 2232, in _create_logged_model\n",
    "    return MlflowClient().create_logged_model(\n",
    "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
    "        experiment_id=experiment_id,\n",
    "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "    ...<4 lines>...\n",
    "        model_type=model_type,\n",
    "        ^^^^^^^^^^^^^^^^^^^^^^\n",
    "    )\n",
    "    ^\n",
    "  File \"/Users/jacek/oss/mlflow/mlflow/tracking/client.py\", line 5218, in create_logged_model\n",
    "    return self._tracking_client.create_logged_model(\n",
    "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
    "        experiment_id, name, source_run_id, tags, params, model_type\n",
    "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "    )\n",
    "    ^\n",
    "  File \"/Users/jacek/oss/mlflow/mlflow/tracking/_tracking_service/client.py\", line 815, in create_logged_model\n",
    "    return self.store.create_logged_model(\n",
    "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
    "        experiment_id=experiment_id,\n",
    "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "    ...<8 lines>...\n",
    "        model_type=model_type,\n",
    "        ^^^^^^^^^^^^^^^^^^^^^^\n",
    "    )\n",
    "    ^\n",
    "  File \"/Users/jacek/oss/mlflow/mlflow/store/tracking/rest_store.py\", line 904, in create_logged_model\n",
    "    response_proto = self._call_endpoint(CreateLoggedModel, req_body)\n",
    "  File \"/Users/jacek/oss/mlflow/mlflow/store/tracking/rest_store.py\", line 129, in _call_endpoint\n",
    "    return call_endpoint(\n",
    "        self.get_host_creds(),\n",
    "    ...<4 lines>...\n",
    "        retry_timeout_seconds=retry_timeout_seconds,\n",
    "    )\n",
    "  File \"/Users/jacek/oss/mlflow/mlflow/utils/rest_utils.py\", line 474, in call_endpoint\n",
    "    response = verify_rest_response(response, endpoint)\n",
    "  File \"/Users/jacek/oss/mlflow/mlflow/utils/rest_utils.py\", line 261, in verify_rest_response\n",
    "    raise RestException(json.loads(response.text))\n",
    "mlflow.exceptions.RestException: BAD_REQUEST: This API is not enabled.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "363e685b-1c47-4b0b-a9db-b281112f1935",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 4. BAD_REQUEST: This API is not enabled.\n",
    "\n",
    "Hunting down the root cause of the exception."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f61ac2dc-dcf4-434a-9e97-4b283ef390d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "Modify `mlflow/utils/rest_utils.py:261`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aaf92b31-e3b2-4d08-ad60-05e0c46e87b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "```\n",
    "‚ùØ python examples/databricks/dbconnect.py --cluster-id xxx\n",
    ">>> endpoint /api/2.0/mlflow/experiments/get-by-name\n",
    ">>> endpoint /api/2.0/mlflow/runs/create\n",
    ">>> endpoint /api/2.0/mlflow/runs/get\n",
    ">>> endpoint /api/2.0/mlflow/logged-models\n",
    ">>> endpoint /api/2.0/mlflow/runs/get\n",
    "üèÉ View run zealous-worm-360 at: https://curriculum-dev.cloud.databricks.com/ml/experiments/1275781889574864/runs/8cad690b9bdd45ab96658987f4039180\n",
    "üß™ View experiment at: https://curriculum-dev.cloud.databricks.com/ml/experiments/1275781889574864\n",
    ">>> endpoint /api/2.0/mlflow/runs/update\n",
    "Traceback (most recent call last):\n",
    "  File \"/Users/jacek/oss/mlflow/examples/databricks/dbconnect.py\", line 56, in <module>\n",
    "    main()\n",
    "    ~~~~^^\n",
    "...\n",
    "  File \"/Users/jacek/oss/mlflow/mlflow/utils/rest_utils.py\", line 262, in verify_rest_response\n",
    "    raise RestException(json.loads(response.text))\n",
    "mlflow.exceptions.RestException: BAD_REQUEST: This API is not enabled.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f688d06-825d-4946-ad6f-d9f3a1d85036",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Step 5. MLflow API reference\n",
    "\n",
    "[MLflow API reference](https://docs.databricks.com/aws/en/reference/mlflow-api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a30c630-8098-4962-80be-ea65a7c6473f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Experiments\n",
    "\n",
    "[Experiments](https://docs.databricks.com/api/workspace/experiments)\n",
    "\n",
    "1. **Experiments** are the primary unit of organization in MLflow.\n",
    "1. All **MLflow runs** belong to an experiment.\n",
    "1. Each experiment lets you visualize, search, and compare runs, as well as download run artifacts or metadata for analysis in other tools.\n",
    "1. Experiments are maintained in a Databricks-hosted MLflow tracking server.\n",
    "1. Experiments are located in the workspace file tree.\n",
    "1. You manage experiments using the same tools you use to manage other workspace objects such as folders, notebooks, and libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "daf3d05b-6449-4175-b5e4-a2aa0c8b4181",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Databricks CLI\n",
    "\n",
    "```\n",
    "‚ùØ databricks |more\n",
    "...\n",
    "Machine Learning\n",
    "  experiments                            Experiments are the primary unit of organization in MLflow; all MLflow runs belong to an experiment.\n",
    "  model-registry                         Note: This API reference documents APIs for the Workspace Model Registry.\n",
    "Real-time Serving\n",
    "  serving-endpoints                      The Serving Endpoints API allows you to create, update, and delete model serving endpoints.\n",
    "Unity Catalog\n",
    "  model-versions                         Databricks provides a hosted version of MLflow Model Registry in Unity Catalog.\n",
    "  registered-models                      Databricks provides a hosted version of MLflow Model Registry in Unity Catalog.\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab938654-1be1-4bc1-b14e-2facc72e688f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "```\n",
    "‚ùØ databricks experiments list-experiments | jq '.[].name' | grep 'jacek@japila.pl'\n",
    "\"/Users/jacek@japila.pl/dbconnect\"\n",
    "\"/Users/jacek@japila.pl/demo-experiment\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3284485d-1989-4277-9985-5bd4950e1820",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "```\n",
    "databricks registered-models list | jq '.[].full_name'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "279bc14e-a8c2-486a-8333-57953da36a3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# What Takes to Execute MLflow's dev/pyproject.py locally\n",
    "\n",
    "1. What I learnt while reviewing the source code of MLflow and having found [dev/pyproject.py](https://github.com/mlflow/mlflow/blob/master/dev/pyproject.py) to execute locally.\n",
    "1. And how uv helped.\n",
    "\n",
    "Why it even matters?! ü§®"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4541cb2-7ccd-48f1-a7c5-e089ff0249fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Step 0. Clone MLflow Repo\n",
    "\n",
    "`git clone` https://github.com/mlflow/mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21a6de9e-bbc6-459f-a816-9075de7661eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Step 1. uvx python dev/pyproject.py\n",
    "\n",
    "<br>\n",
    "\n",
    "```\n",
    "‚ùØ uvx python dev/pyproject.py\n",
    "Traceback (most recent call last):\n",
    "  File \"/Users/jacek/oss/mlflow/./dev/pyproject.py\", line 10, in <module>\n",
    "    import toml\n",
    "ModuleNotFoundError: No module named 'toml'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd677538-0c44-41b5-9704-c9ec9ec5af1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Step 2. Set Up Dev Env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d9114378-111e-4ea6-9b96-486c9586b80f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "`uv venv .dev_pyproject_py_deep_dive`\n",
    "\n",
    "`source .dev_pyproject_py_deep_dive/bin/activate`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "897bcf7b-c9bf-4353-8e58-509ce852a7c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Step 3. Virtual Envs in Python\n",
    "\n",
    "Please note that I'm a JVM dev (and only very recently switched to Python)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd02cf1b-7c34-4086-ba68-55fd3320004c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "`uv pip install toml`\n",
    "\n",
    "`python ./dev/pyproject.py`\n",
    "\n",
    "`type python` and it finally clicked how virtual envs work üî•\n",
    "\n",
    "[venv ‚Äî Creation of virtual environments](https://docs.python.org/3/library/venv.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0034a39a-78d4-4e12-b703-f724b5dec8c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 4. It Works ü•≥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "861b6039-d158-42b1-94ec-d04bb582b99e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "`uv pip install pyyaml`\n",
    "\n",
    "> ‚ö†Ô∏è NOTE\n",
    ">\n",
    "> All the dev deps are in [dev/requirements.txt](https://github.com/mlflow/mlflow/blob/master/dev/requirements.txt)\n",
    "\n",
    "`uv pip install packaging`\n",
    "\n",
    "`brew install taplo`\n",
    "\n",
    "`python ./dev/pyproject.py` seems to change nothing, huh?! ü§®\n",
    "\n",
    "üíé Think what the script does and you will know why nothing seems changed üòâ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "55e65a92-b63c-4c0a-ac4f-9e47b0336da7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## That's all Folks üëã\n",
    "\n",
    "![Warner Bros., Public domain, via Wikimedia Commons](https://upload.wikimedia.org/wikipedia/commons/e/ea/Thats_all_folks.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d7b14c19-aa2c-42f1-9fa1-4d093367d994",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# üí° Ideas for Future Events\n",
    "\n",
    "1. [Delta Live Tables](https://docs.databricks.com/en/delta-live-tables/index.html) with uv and pydantic\n",
    "1. Explore more [Pydantic](https://docs.pydantic.dev/latest/) features\n",
    "1. Create a new DAB template with `uv` as the project management tool (based on `default-python` template). Start from `databricks bundle init --help`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4388217a-e666-4b22-b5b0-410c8a472803",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## MLflow Prompt Registry\n",
    "\n",
    "In [MLflow 2.21.0](https://github.com/mlflow/mlflow/releases/tag/v2.21.0):\n",
    "\n",
    ">  **Prompt Registry**: MLflow Prompt Registry is a powerful tool that streamlines prompt engineering and management in your GenAI applications. It enables you to version, track, and reuse prompts across your organization.\n",
    "\n",
    "[MLflow Prompt Registry](https://mlflow.org/docs/latest/prompts/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e4b7010-4e5d-4d18-a094-fbd933383d86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## MLflow Tracing\n",
    "\n",
    "In [MLflow 2.21.0](https://github.com/mlflow/mlflow/releases/tag/v2.21.0):\n",
    "\n",
    ">  **Enhanced Tracing Capabilities**: MLflow Tracing now supports synchronous/asynchronous generators and auto-tracing for Async OpenAI, providing more flexible and comprehensive tracing options.\n",
    "\n",
    "[MLflow Tracing for LLM Observability](https://mlflow.org/docs/latest/tracing/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cdf5c80f-d447-42bb-87c1-f5c69c60de93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Databricks Asset Bundles and Library Dependencies\n",
    "\n",
    "[PyPI package](https://docs.databricks.com/aws/en/dev-tools/bundles/library-dependencies#pypi-package)\n",
    "\n",
    "Databricks CLI v0.244.0: [Support all version identifiers as per PEP440 in environment deps](https://github.com/databricks/cli/releases/tag/v0.244.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2107f19e-0108-44be-b9c2-ad3dda8c636a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Databricks Asset Bundles and Set the target catalog and schema\n",
    "\n",
    "Databricks CLI v0.243.0: [Use schema field for pipeline in builtin template](https://github.com/databricks/cli/releases/tag/v0.243.0):\n",
    "\n",
    "> The schema field implies the lifecycle of tables is no longer tied to the lifecycle of the pipeline, as was the case with the target field.\n",
    "\n",
    "[Set the target catalog and schema](https://docs.databricks.com/aws/en/dlt/target-schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "451a66d0-4bf7-47f7-a20d-95af43f46808",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## uv with PyTorch\n",
    "\n",
    "uv 0.6.9: [Add experimental --torch-backend to the PyTorch guide](https://github.com/astral-sh/uv/releases/tag/0.6.9)\n",
    "\n",
    "[Using uv with PyTorch](https://docs.astral.sh/uv/guides/integration/pytorch/)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Meetup_2025_05_15",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
