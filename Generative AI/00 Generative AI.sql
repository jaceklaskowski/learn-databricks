-- Databricks notebook source
-- MAGIC %md # Generative AI and Large Language Models
-- MAGIC
-- MAGIC Gain more ground in **Generative AI** (#GenAI) and **Large Language Models** (#LLM) that I know nothing about to become pick as many as could please you (these I found while reading some articles about the subject ðŸ˜Ž):
-- MAGIC
-- MAGIC * A passionate GenAI and LLM enthusiast
-- MAGIC * A seasoned GenAI and LLM professional

-- COMMAND ----------

-- MAGIC %md
-- MAGIC
-- MAGIC There are four [Generative AI Architecture Patterns](https://www.databricks.com/product/machine-learning/build-generative-ai) to consider when building a large language modelâ€“based solution:
-- MAGIC
-- MAGIC 1. [Prompt Engineering]($./Prompt Engineering)
-- MAGIC 1. [Retrieval Augmented Generation (RAG)]($./Retrieval Augmented Generation)
-- MAGIC 1. Fine-tuning
-- MAGIC 1. Pretraining

-- COMMAND ----------

-- MAGIC %md
-- MAGIC
-- MAGIC ## Mosaic AI Agent Framework and Agent Evaluation
-- MAGIC
-- MAGIC RAG applications and Agents are the most popular GenAI applications on Databricks (built using [Mosaic AI Agent Framework and Agent Evaluation](https://www.databricks.com/blog/announcing-mosaic-ai-agent-framework-and-agent-evaluation))

-- COMMAND ----------

-- MAGIC %md ## Use Cases
-- MAGIC
-- MAGIC * Doc Q&A
-- MAGIC * Chatbots

-- COMMAND ----------

-- MAGIC %md ## Other Branches of Machine Learning
-- MAGIC
-- MAGIC * Predictive and Prescriptive Analytics
-- MAGIC * Computer Vision
-- MAGIC * Natural Language Processing
-- MAGIC * Deployment / ML Ops / Cloud
-- MAGIC * Reinforcement Learning
-- MAGIC

-- COMMAND ----------

-- MAGIC %md ## Large Language Models (LLMs)
-- MAGIC
-- MAGIC * ChatGPT
-- MAGIC * [BloombergGPT](https://www.bloomberg.com/company/press/bloomberggpt-50-billion-parameter-llm-tuned-finance/) - Bloombergâ€™s 50-billion parameter large language model, purpose-built from scratch for finance
-- MAGIC * [M0deler](https://m0deler.com/)
-- MAGIC

-- COMMAND ----------

-- MAGIC %md 
-- MAGIC
-- MAGIC Generative AI and Large Language Models (LLMs):
-- MAGIC
-- MAGIC * [OpenAI](https://openai.com/)
-- MAGIC * Local and on-premise models
-- MAGIC * the Rise of Generative AI due to ChatGPT
-- MAGIC * general-purpose chat bots
-- MAGIC * Building products that use LLMs and GenAI
-- MAGIC * Developing apps with GenAI and LLMs

-- COMMAND ----------

-- MAGIC %md ## Prompt Engineering

-- COMMAND ----------

-- MAGIC %md
-- MAGIC
-- MAGIC * Writing ChatGPT prompts
-- MAGIC * the no-code method for writing ChatGPT prompts

-- COMMAND ----------

-- MAGIC %md
-- MAGIC
-- MAGIC ## Databricks Generative AI Fundamentals Learning Plan
-- MAGIC
-- MAGIC [Generative AI Fundamentals](https://www.databricks.com/resources/learn/training/generative-ai-fundamentals)

-- COMMAND ----------

-- MAGIC %md ## Recommended Reading by ChatGPT 3.5
-- MAGIC
-- MAGIC There are the academic papers recommended by [ChatGPT 3.5](https://chat.openai.com/share/3dfac550-eeb6-4740-b68e-52140632edc0) that were instrumental in advancing large language models:
-- MAGIC
-- MAGIC ### Attention Is All You Need
-- MAGIC
-- MAGIC Started my journey into academic paper reading and LLMs from [Attention Is All You Need](https://arxiv.org/abs/1706.03762) by Vaswani et al. (2017) as _"This paper introduced the Transformer architecture, which revolutionized the field of NLP and laid the foundation for large language models like GPT and BERT."_
